# Bifrost Core - Umbrella Chart Configuration
# This chart can be consumed by bifrost-config as a dependency

# Global configuration shared across all subcharts
global:
  # Namespace for all bifrost-core components
  namespace: bifrost-core

  # Image pull secrets
  imagePullSecrets: []

  # Storage class for persistent volumes
  storageClass: ""

  # Object Storage Configuration (shared across all components)
  objectStorage:
    # Type: s3, minio, azure, gcs
    type: s3
    endpoint: "s3.amazonaws.com"
    bucket: "bifrost-data"
    region: "us-east-1"
    pathStyleAccess: false

    # Warehouse directory
    warehouse: "/warehouse"

    # SSL/TLS
    ssl:
      enabled: true

    # Credentials secret
    credentials:
      existingSecret: "s3-credentials"
      accessKeyKey: "access-key"
      secretKeyKey: "secret-key"

  # Metastore endpoint (shared by Spark and Trino)
  # Note: When used in bifrost-config, override this with the actual service name
  metastore:
    uri: "thrift://bifrost-core-metastore:9083"

# Hive Metastore subchart configuration
metastore:
  enabled: true

  hive:
    image:
      repository: apache/hive
      tag: "3.1.3"
      pullPolicy: IfNotPresent

    replicaCount: 1

    service:
      type: ClusterIP
      port: 9083
      name: hive-metastore

    resources:
      requests:
        memory: "1Gi"
        cpu: "500m"
      limits:
        memory: "2Gi"
        cpu: "1000m"

  # PostgreSQL backend for metastore
  # WARNING: Default credentials below are for development only!
  # Override these in bifrost-config for production environments
  postgresql:
    enabled: true
    auth:
      username: hive
      password: hive  # CHANGE THIS IN PRODUCTION
      database: metastore
    primary:
      persistence:
        enabled: true
        size: 20Gi
      resources:
        requests:
          memory: "256Mi"
          cpu: "250m"
        limits:
          memory: "1Gi"
          cpu: "1000m"

  bifrost:
    init:
      enabled: true
      createDatabase: true
      runSchematool: true

# Spark Operator subchart configuration
spark-operator:
  enabled: true

  # Upstream spark-operator chart config
  spark-operator:
    image:
      registry: ghcr.io
      repository: kubeflow/spark-operator/controller
      tag: ""  # Uses chart appVersion (2.3.0)
      pullPolicy: IfNotPresent

    replicaCount: 1

    serviceAccounts:
      spark:
        create: true
        name: spark
      sparkoperator:
        create: true
        name: spark-operator

    # Configure which namespaces the operator watches for SparkApplications
    spark:
      jobNamespaces:
        - default
        - bifrost-core
        - bifrost-example

    webhook:
      enable: true
      port: 9443  # Default port to avoid conflict with metrics

    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 100m
        memory: 128Mi

    metrics:
      enable: true
      port: 10254

    logLevel: 2

  # Bifrost-specific Spark configuration
  bifrost:
    sparkImage:
      repository: docker.io/library/spark
      tag: "4.0.0"
      pullPolicy: IfNotPresent

    sparkVersion: "4.0.0"

    defaults:
      driver:
        cores: 1
        memory: "1g"
        serviceAccount: spark
      executor:
        cores: 1
        instances: 2
        memory: "1g"

    formats:
      delta:
        enabled: true
        version: "3.0.0"
      iceberg:
        enabled: true
        version: "1.4.3"
      hudi:
        enabled: true
        version: "0.14.1"

# Trino subchart configuration
trino:
  enabled: true

  # Upstream trino chart config
  trino:
    image:
      repository: trinodb/trino
      tag: "431"
      pullPolicy: IfNotPresent

    server:
      workers: 2

      coordinator:
        jvm:
          maxHeapSize: "8G"
          gcMethod:
            type: "UseG1GC"
            g1:
              heapRegionSize: "32M"
        config:
          memory:
            heapHeadroomPerNode: "1GB"
          query:
            maxMemory: "4GB"
            maxMemoryPerNode: "1GB"

      worker:
        jvm:
          maxHeapSize: "8G"
          gcMethod:
            type: "UseG1GC"
            g1:
              heapRegionSize: "32M"
        config:
          memory:
            heapHeadroomPerNode: "1GB"
          query:
            maxMemoryPerNode: "1GB"

    coordinator:
      resources:
        requests:
          memory: "4Gi"
          cpu: "2"
        limits:
          memory: "8Gi"
          cpu: "4"

    worker:
      resources:
        requests:
          memory: "4Gi"
          cpu: "2"
        limits:
          memory: "8Gi"
          cpu: "4"

    service:
      type: ClusterIP
      port: 8080

    # Lakehouse catalogs
    additionalCatalogs:
      iceberg: |
        connector.name=iceberg
        iceberg.catalog.type=hive_metastore
        hive.metastore.uri=thrift://bifrost-core-metastore:9083
        iceberg.file-format=PARQUET
        iceberg.compression-codec=SNAPPY

      delta: |
        connector.name=delta_lake
        hive.metastore.uri=thrift://bifrost-core-metastore:9083
        delta.enable-non-concurrent-writes=true

      hudi: |
        connector.name=hudi
        hive.metastore.uri=thrift://bifrost-core-metastore:9083

# Monitoring Configuration
monitoring:
  enabled: true

  prometheus:
    enabled: true
    serviceMonitor:
      enabled: true

  grafana:
    enabled: true
    dashboards:
      enabled: true

# Security Configuration
security:
  rbac:
    enabled: true

  networkPolicies:
    enabled: false

  podSecurityPolicy:
    enabled: false

# Resource Management
resources:
  quota:
    enabled: false
    requests:
      cpu: "100"
      memory: "200Gi"
    limits:
      cpu: "200"
      memory: "400Gi"

  limitRange:
    enabled: false
